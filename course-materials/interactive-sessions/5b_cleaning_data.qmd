---
title: "Interactive Session 5B"
subtitle: "Cleaning Data"
editor_options: 
  chunk_output_type: console
jupyter: eds217_2024
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: show
---

::: {style="width: 60%; margin: auto;"}
![](images/cleaning.png)
:::

:::{.gray-text .center-text}
*A cartoon panda is getting a bubble bath.* [MidJourney 5](https://www.midjourney.com/jobs/2a08bcac-24e3-4c73-ad14-4733c1ffd363?index=0)
:::


## Introduction to Data Cleaning

Data cleaning is a crucial step in the data science workflow. It involves identifying and correcting errors, inconsistencies, and inaccuracies in datasets to ensure the quality and reliability of your analysis.

In this session, we'll explore common issues in dataframes and learn how to address them using pandas. 


## Instructions
We will work through this material together, writing a new notebook as we go.


<p style="color:#008C96; font-weight: bold"> ‚úèÔ∏è &nbsp; &nbsp; This symbol designates code you should add to your notebook and run.  </p>

ü§ì Where useful, this session contains links to [Pandas Tutor](https://pandastutor.com/index.html), which helps you to visualize the chained functions in the accompanying code block.

<hr style="border-top: 1px solid gray; margin-top: 24px; margin-bottom: 1px"></hr>


Let's start by importing pandas and creating a sample dataframe with some issues we'll need to clean:

<div class="example"> 
‚úèÔ∏è Try it. Add the cell below to your notebook and run it.
</div>

```{python}
#| echo: true
import pandas as pd
import numpy as np

# Create a sample dataframe with issues
data = {
    'species': ['Oak', 'Pine', 'Maple', 'Oak', 'Pine', None],
    'height_m': [5.2, 12.0, '7.5', 5.2, 15.0, 8.1],
    'diameter_cm': [20, 35, 25, 20, 40, np.nan],
    'location': ['Park A', 'Park B', 'Park A', 'Park A', 'Park B', 'Park C '],
    'date_planted': ['2020-01-15', '2019-05-20', '2020-03-10', '2020-01-15', '2018-11-30', '2021-07-05']
}

df = pd.DataFrame(data)
print(df)
```

## Handling Missing Values

### Identifying Missing Values

First, let's check for missing values in our dataframe. For this we use the `isnull()` method on the dataframe.

<div class="example"> 
‚úèÔ∏è Try it. Add the cell below to your notebook and run it.
</div>

```{python}
#| echo: true
print(df.isnull())
```

You can see that the `isnull()` command returns a Booelan (`True` or `False`) value for each item in the dataframe. If the location (row, column) is empty, then the `isnull()` command will return `True`, otherwise it returns `False`.

We can apply the `sum()` method to the result of `df.isnull()` to see what columns have empty values in them. 

:::{.callout-important}
The `axis` argument is often used in pandas and numpy to indicate how an aggregation (e.g. `sum()`) should be applied. You should read this argument as an answer to the question:

> What should I apply this aggregation across, `rows` or `columns`?

`df.sum(axis='rows')` adds up all the rows and <i>returns a single sum for each column</i>.

`df.sum(axis='columns')` adds up all the columns and <i>returns a single sum for each row</i>. 

Generally, aggregations over all rows are more useful than aggregations across all columns, so the _default_ for pandas and numpy aggregations is to apply aggregations and dataframe operations assuming `axis='rows'`. However, as we'll see, other commands default to `axis='columns'`
:::

<div class="example"> 
‚úèÔ∏è Try it. Add the cell below to your notebook and run it.
</div>

```{python}
#| echo: true

null_values = df.isnull()
print(null_values.sum(axis='rows'))
```

As we requested, this command sums up all the rows in each column of `null_values`. Any `False` is a `0` and any `True` is a `1`, so the result is the number of null values in each column of the dataframe.

:::{.callout-info}
Method chaining allows us to do both the finding of null values and the summing of values for all rows in each column with a single line of code
:::

<div class="example"> 
‚úèÔ∏è Try it. Add the cell below to your notebook and run it.
</div>

```{python}
#| echo: true
# Use method chaining to make our code more concise.
df.isnull().sum(axis='rows')
```

ü§ì [Pandas Tutor](https://pandastutor.com/vis.html#code=import%20pandas%20as%20pd%0Aimport%20numpy%20as%20np%0A%23%20Create%20a%20sample%20dataframe%20with%20issues%0Adata%20%3D%20%7B%0A%20%20%20%20'species'%3A%20%5B'Oak',%20'Pine',%20'Maple',%20'Oak',%20'Pine',%20None%5D,%0A%20%20%20%20'height_m'%3A%20%5B5.2,%2012.0,%20'7.5',%205.2,%2015.0,%208.1%5D,%0A%20%20%20%20'diameter_cm'%3A%20%5B20,%2035,%2025,%2020,%2040,%20np.nan%5D,%0A%20%20%20%20'location'%3A%20%5B'Park%20A',%20'Park%20B',%20'Park%20A',%20'Park%20A',%20'Park%20B',%20'Park%20C'%5D,%0A%20%20%20%20'date_planted'%3A%20%5B'2020-01-15',%20'2019-05-20',%20'2020-03-10',%20'2020-01-15',%20'2018-11-30',%20'2021-07-05'%5D%0A%7D%0Adf%20%3D%20pd.DataFrame%28data%29%0A%0Adf.isnull%28%29.sum%28axis%3D'rows'%29&d=2024-08-28&lang=py&v=v1)

### Dropping Missing Values

We can drop rows with missing values using the `dropna()` function:

```{python}
#| echo: true
df_dropped = df.dropna()
print(df_dropped)
```

Notice how we didn't need to specify an axis - by default, `dropna()` operates on each row and removes and rows that are any missing values (the default is `axis='rows'`). 

### Filling Missing Values

If we don't want to remove rows that are missing data, we can instead fill missing values using various methods.

<div class="example"> 
‚úèÔ∏è Try it. Add the cell below to your notebook and run it.
</div>

```{python}
#| echo: true
# Fill missing values with a specific value
df['species'] = df['species'].fillna('unknown')

print(df)
```

We can even use aggregations to fill with values derived from our dataframe. 

For example, let's replace missing values of `diameter_cm` with the average value across all the rows.

<div class="example"> 
‚úèÔ∏è Try it. Add the cell below to your notebook and run it.
</div>

```{python}
#| echo: true
# Fill missing numeric values with the mean of the column
df['diameter_cm'] = df['diameter_cm'].fillna(df['diameter_cm'].mean())
```

ü§ì [Pandas Tutor](https://pandastutor.com/vis.html#code=import%20pandas%20as%20pd%0Aimport%20numpy%20as%20np%0A%23%20Create%20a%20sample%20dataframe%20with%20issues%0Adata%20%3D%20%7B%0A%20%20%20%20'species'%3A%20%5B'Oak',%20'Pine',%20'Maple',%20'Oak',%20'Pine',%20None%5D,%0A%20%20%20%20'height_m'%3A%20%5B5.2,%2012.0,%20'7.5',%205.2,%2015.0,%208.1%5D,%0A%20%20%20%20'diameter_cm'%3A%20%5B20,%2035,%2025,%2020,%2040,%20np.nan%5D,%0A%20%20%20%20'location'%3A%20%5B'Park%20A',%20'Park%20B',%20'Park%20A',%20'Park%20A',%20'Park%20B',%20'Park%20C'%5D,%0A%20%20%20%20'date_planted'%3A%20%5B'2020-01-15',%20'2019-05-20',%20'2020-03-10',%20'2020-01-15',%20'2018-11-30',%20'2021-07-05'%5D%0A%7D%0Adf%20%3D%20pd.DataFrame%28data%29%0A%0Adf%5B'diameter_cm'%5D.fillna%28df%5B'diameter_cm'%5D.mean%28%29%29&d=2024-08-28&lang=py&v=v1)

## Dealing with Duplicates

### Identifying and Removing Duplicate Rows

Let's check for and remove duplicate rows:

<div class="example"> 
‚úèÔ∏è Try it. Add the cell below to your notebook and run it.
</div>

```{python}
#| echo: true
# Check for duplicates
print(df.duplicated())
```

It looks like row `3` is a duplicate (it is the same as row `0`). As before, we can see how many rows are duplicated by applying the sum command to the result of `df.duplicated()`

<div class="example"> 
‚úèÔ∏è Try it. Add the cell below to your notebook and run it.
</div>

```{python}
#| echo: true
df.duplicated().sum()
```

ü§ì [Pandas Tutor](https://pandastutor.com/vis.html#code=import%20pandas%20as%20pd%0Aimport%20numpy%20as%20np%0A%23%20Create%20a%20sample%20dataframe%20with%20issues%0Adata%20%3D%20%7B%0A%20%20%20%20'species'%3A%20%5B'Oak',%20'Pine',%20'Maple',%20'Oak',%20'Pine',%20None%5D,%0A%20%20%20%20'height_m'%3A%20%5B5.2,%2012.0,%20'7.5',%205.2,%2015.0,%208.1%5D,%0A%20%20%20%20'diameter_cm'%3A%20%5B20,%2035,%2025,%2020,%2040,%20np.nan%5D,%0A%20%20%20%20'location'%3A%20%5B'Park%20A',%20'Park%20B',%20'Park%20A',%20'Park%20A',%20'Park%20B',%20'Park%20C'%5D,%0A%20%20%20%20'date_planted'%3A%20%5B'2020-01-15',%20'2019-05-20',%20'2020-03-10',%20'2020-01-15',%20'2018-11-30',%20'2021-07-05'%5D%0A%7D%0Adf%20%3D%20pd.DataFrame%28data%29%0A%0Adf.duplicated%28%29.sum%28%29&d=2024-08-28&lang=py&v=v1)

The `drop_duplicates()` method returns a new dataframe that only contains the first row of any duplicated rows.

<div class="example"> 
‚úèÔ∏è Try it. Add the cell below to your notebook and run it.
</div>

```{python}
#| echo: true
df_no_duplicates = df.drop_duplicates()
print(df_no_duplicates)
```

The extra entry for `Oak` no longer appears in `df_no_duplicates`.

:::{.callout-info}
What if we wanted to simply get rid of the duplicates in our original `df` without having to make an entirely new dataframe? the `inplace` option allows for this with many pandas methods:

df.drop_duplicates(inplace=True)
:::

<div class="example"> 
‚úèÔ∏è Try it. Add the cell below to your notebook and run it.
</div>

```{python}
#| echo: true
# Make a copy of our dataframe
df2 = df.copy()
# Remove the duplicates from df2 without making a new dataframe (save results back into df2)
df2.drop_duplicates(inplace=True)
print(df2)
```


### Handling Duplicates Based on Specific Columns

We can also remove duplicates based on specific columns, in this case removing any rows that share the same `species` and `location`.

<div class="example"> 
‚úèÔ∏è Try it. Add the cell below to your notebook and run it.
</div>

```{python}
#| echo: true
df_unique_species = df.drop_duplicates(subset=['species', 'location'])
print(df_unique_species)
```

Although our two Pines weren't duplciates (their `height_m`, `diameter_cm`, and `date_planted` were different), we still dropped them from the dataframe based on the subset of columns (`species` and `location`)

ü§ì [Pandas Tutor](https://pandastutor.com/vis.html#code=import%20pandas%20as%20pd%0Aimport%20numpy%20as%20np%0A%23%20Create%20a%20sample%20dataframe%20with%20issues%0Adata%20%3D%20%7B%0A%20%20%20%20'species'%3A%20%5B'Oak',%20'Pine',%20'Maple',%20'Oak',%20'Pine',%20None%5D,%0A%20%20%20%20'height_m'%3A%20%5B5.2,%2012.0,%20'7.5',%205.2,%2015.0,%208.1%5D,%0A%20%20%20%20'diameter_cm'%3A%20%5B20,%2035,%2025,%2020,%2040,%20np.nan%5D,%0A%20%20%20%20'location'%3A%20%5B'Park%20A',%20'Park%20B',%20'Park%20A',%20'Park%20A',%20'Park%20B',%20'Park%20C'%5D,%0A%20%20%20%20'date_planted'%3A%20%5B'2020-01-15',%20'2019-05-20',%20'2020-03-10',%20'2020-01-15',%20'2018-11-30',%20'2021-07-05'%5D%0A%7D%0Adf%20%3D%20pd.DataFrame%28data%29%0A%0Adf.drop_duplicates%28subset%3D%5B'species',%20'location'%5D%29&d=2024-08-28&lang=py&v=v1)

## Data Type Conversion and Consistency

### Checking and Changing Data Types

Often datasets - especially those collected by surveys or forms - contain a mixture of data types (i.e. some strings mixed in with mostly numbers)

Let's check the data types of our columns and convert them as needed:

<div class="example"> 
‚úèÔ∏è Try it. Add the cell below to your notebook and run it.
</div>

```{python}
#| echo: true
print(df.dtypes)

```

The `object` datatype is a generic term meaning "something, I don't know what" in python (remember, in python _everything is an object_).

Generally, we want our data types to be something more specific, like a floating point number, an integer, a string, or a date. We can use the `astype()` method to coerce our data into a specific kind of thing.

:::{.callout-info}
In older versions of pandas, string columns were always still listed as type `object`. They are functionally `str` objects, but pandas isn't storing them in any special "pandas" way, so they are just generic python `object`s. Newer versions of pandas allow you to create `string` (note: not the same as `str`) data types. They are optimized for use in pandas, although you will rarely see any difference in performance, it's good practice to use them when you can.
:::

Let's convert `height_m` to `float`.

<div class="example"> 
‚úèÔ∏è Try it. Add the cell below to your notebook and run it.
</div>

```{python}
#| echo: true
# Convert 'height_m' to float
df['height_m'] = df['height_m'].astype(float)
print(df.dtypes)
```

Converting generic objects to `datetime` is more complicated. In fact, we'll have an entire session later this class on working with dates. Pandas has a helper function - `pd.to_datetime()` - that tries to infer dates from values in columns.  

<div class="example"> 
‚úèÔ∏è Try it. Add the cell below to your notebook and run it.
</div>

```{python}
#| echo: true
# Convert 'date_planted' to datetime
df['date_planted'] = pd.to_datetime(df['date_planted'])

print(df.dtypes)
```

## String Manipulation and Formatting

We can use string methods to clean text data. We access these methods using the `.str` attribute that is part of every pandas `Series`.

:::{.callout-note}
Remember, every column in a `DataFrame` is a `Series`
:::

<div class="example"> 
‚úèÔ∏è Try it. Add the cell below to your notebook and run it.
</div>

```{python}
#| echo: true
print("'unkown' should be capitalized")
print(df)

# Capitalize species names (unknown -> Unknown)
df['species'] = df['species'].str.capitalize()

print("\nFixed it!")
print(df)
```

<div class="example"> 
‚úèÔ∏è Try it. Add the cell below to your notebook and run it.
</div>

```{python}
#| echo: true
print("'Park C ' should be 'Park C'")
print(df)

# Remove leading/trailing whitespace from location
# "Park C " -> "Park C"
df['location'] = df['location'].str.strip()

print("\nFixed it!")
print(df)
```

## Wrap-up and Best Practices

In this session, we've covered essential techniques for cleaning dataframes in pandas:
- Handling missing values
- Dealing with duplicates
- Converting data types
- String manipulation and formatting

Remember these best practices:
1. Always examine your data before and after cleaning steps.
2. Use descriptive keyword arguments like 'subset' for columns and 'axis' for rows/columns to make your code more readable.
3. Document your cleaning steps for reproducibility.
4. Be cautious when dropping data - sometimes imputation or other techniques might be more appropriate.

For more advanced cleaning techniques and in-depth explanations, refer to the pandas documentation [Pandas Documentation](https://pandas.pydata.org/docs/), the master [Pandas Cheat Sheet](Pandas_Cheat_Sheet.pdf), or our class [Cleaning Data Cheatsheet](../cheatsheets/data_cleaning.qmd)

::: {.center-text .body-text-xl .teal-text}
End interactive session 5B
:::
